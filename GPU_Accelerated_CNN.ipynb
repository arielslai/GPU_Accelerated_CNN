{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# GPU-Accelerated CNN Training on CIFAR-10 (PyTorch + CUDA)\n",
        "\n",
        "This project benchmarks the performance difference between CPU and GPU training for a small convolutional neural network (CNN) on the CIFAR-10 dataset.  \n",
        "\n",
        "Using PyTorch with CUDA in Google Colab, the model was trained on both CPU and GPU to measure training time and accuracy.  \n",
        "Results highlight the practical speedup enabled by GPU acceleration in deep learning workflows.\n"
      ],
      "metadata": {
        "id": "Pl6V2EhqYV8z"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Verifying CUDA"
      ],
      "metadata": {
        "id": "YxLpXoggX-KS"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LKL8NBovXfov",
        "outputId": "c9343f33-60aa-4978-be4b-6389283a9247"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Torch: 2.5.1+cu121 | CUDA available: True\n",
            "Sat Aug 16 05:44:15 2025       \n",
            "+-----------------------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 550.54.15              Driver Version: 550.54.15      CUDA Version: 12.4     |\n",
            "|-----------------------------------------+------------------------+----------------------+\n",
            "| GPU  Name                 Persistence-M | Bus-Id          Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |\n",
            "|                                         |                        |               MIG M. |\n",
            "|=========================================+========================+======================|\n",
            "|   0  Tesla T4                       Off |   00000000:00:04.0 Off |                    0 |\n",
            "| N/A   55C    P8             11W /   70W |       2MiB /  15360MiB |      0%      Default |\n",
            "|                                         |                        |                  N/A |\n",
            "+-----------------------------------------+------------------------+----------------------+\n",
            "                                                                                         \n",
            "+-----------------------------------------------------------------------------------------+\n",
            "| Processes:                                                                              |\n",
            "|  GPU   GI   CI        PID   Type   Process name                              GPU Memory |\n",
            "|        ID   ID                                                               Usage      |\n",
            "|=========================================================================================|\n",
            "|  No running processes found                                                             |\n",
            "+-----------------------------------------------------------------------------------------+\n"
          ]
        }
      ],
      "source": [
        "import torch, torchvision, sys, platform\n",
        "print(\"Torch:\", torch.__version__, \"| CUDA available:\", torch.cuda.is_available())\n",
        "!nvidia-smi"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Installing/confirming libs"
      ],
      "metadata": {
        "id": "mdeGlG8PYHLH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip -q install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu121\n"
      ],
      "metadata": {
        "id": "oUV_qOeHX7kr"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Set up data + transforms"
      ],
      "metadata": {
        "id": "UhwGPtY2YMMV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch, torchvision\n",
        "from torchvision import transforms, datasets\n",
        "from torch.utils.data import DataLoader\n",
        "\n",
        "BATCH_SIZE = 128\n",
        "\n",
        "transform = transforms.Compose([\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.4914,0.4822,0.4465),(0.2470,0.2435,0.2616))\n",
        "])\n",
        "\n",
        "trainset = datasets.CIFAR10(root=\"./data\", train=True,  download=True, transform=transform)\n",
        "testset  = datasets.CIFAR10(root=\"./data\", train=False, download=True, transform=transform)\n",
        "trainloader = DataLoader(trainset, batch_size=BATCH_SIZE, shuffle=True, num_workers=2, pin_memory=True)\n",
        "testloader  = DataLoader(testset,  batch_size=256, shuffle=False, num_workers=2, pin_memory=True)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mwxpo0tqYUcd",
        "outputId": "55de978a-59e5-4c7a-976a-8ca9d0c4f852"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Files already downloaded and verified\n",
            "Files already downloaded and verified\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Defining a tiny CNN"
      ],
      "metadata": {
        "id": "NaMQQXKDYswk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.nn as nn\n",
        "\n",
        "class SmallCNN(nn.Module):\n",
        "    def __init__(self, num_classes=10):\n",
        "        super().__init__()\n",
        "        self.net = nn.Sequential(\n",
        "            nn.Conv2d(3, 32, 3, padding=1), nn.ReLU(), nn.MaxPool2d(2),\n",
        "            nn.Conv2d(32,64,3, padding=1), nn.ReLU(), nn.MaxPool2d(2),\n",
        "            nn.Conv2d(64,128,3, padding=1), nn.ReLU(), nn.AdaptiveAvgPool2d((1,1))\n",
        "        )\n",
        "        self.fc = nn.Linear(128, num_classes)\n",
        "    def forward(self, x):\n",
        "        x = self.net(x)\n",
        "        return self.fc(x.view(x.size(0), -1))"
      ],
      "metadata": {
        "id": "Wvqnwsk-YwxF"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Train+time helper definition"
      ],
      "metadata": {
        "id": "USKcEGKeY48h"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import time\n",
        "import torch.optim as optim\n",
        "import torch.nn.functional as F\n",
        "\n",
        "def train_and_time(device, epochs=2):\n",
        "    model = SmallCNN().to(device)\n",
        "    opt = optim.Adam(model.parameters(), lr=1e-3)\n",
        "    start = time.time()\n",
        "    for ep in range(epochs):\n",
        "        model.train()\n",
        "        for x,y in trainloader:\n",
        "            x, y = x.to(device, non_blocking=True), y.to(device, non_blocking=True)\n",
        "            opt.zero_grad()\n",
        "            loss = F.cross_entropy(model(x), y)\n",
        "            loss.backward()\n",
        "            opt.step()\n",
        "    # IMPORTANT: make sure all CUDA work is finished before timing\n",
        "    if device.type == \"cuda\":\n",
        "        torch.cuda.synchronize()\n",
        "    train_time = time.time() - start\n",
        "\n",
        "    # quick test accuracy\n",
        "    model.eval()\n",
        "    correct = total = 0\n",
        "    with torch.no_grad():\n",
        "        for x,y in testloader:\n",
        "            x, y = x.to(device, non_blocking=True), y.to(device, non_blocking=True)\n",
        "            logits = model(x)\n",
        "            pred = logits.argmax(1)\n",
        "            correct += (pred==y).sum().item()\n",
        "            total += y.size(0)\n",
        "    acc = 100*correct/total\n",
        "    return train_time, acc\n"
      ],
      "metadata": {
        "id": "b8bbSzRYY9VA"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Running CPU vs GPU"
      ],
      "metadata": {
        "id": "0lS5ClJUZLBx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "cpu_epochs = 2\n",
        "gpu_epochs = 20\n",
        "\n",
        "cpu_time, cpu_acc = train_and_time(torch.device(\"cpu\"), epochs=cpu_epochs)\n",
        "print(f\"CPU:   {cpu_time:.1f}s total for {cpu_epochs} ep, acc={cpu_acc:.2f}%\")\n",
        "\n",
        "if torch.cuda.is_available():\n",
        "    gpu_time, gpu_acc = train_and_time(torch.device(\"cuda\"), epochs=gpu_epochs)\n",
        "    print(f\"GPU:   {gpu_time:.1f}s total for {gpu_epochs} ep, acc={gpu_acc:.2f}%\")\n",
        "\n",
        "    # seconds per epoch\n",
        "    cpu_sec_per_ep = cpu_time / cpu_epochs\n",
        "    gpu_sec_per_ep = gpu_time / gpu_epochs\n",
        "\n",
        "    print(f\"CPU: {cpu_sec_per_ep:.2f}s/epoch\")\n",
        "    print(f\"GPU: {gpu_sec_per_ep:.2f}s/epoch\")\n",
        "\n",
        "    # apples-to-apples speedup\n",
        "    print(f\"Speedup (per-epoch): {cpu_sec_per_ep / gpu_sec_per_ep:.1f}×\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vAIsz3OKZNnh",
        "outputId": "c24258b9-7f6c-4105-cf23-40f194af8436"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CPU:   133.8s total for 2 ep, acc=48.71%\n",
            "GPU:   242.9s total for 20 ep, acc=72.05%\n",
            "CPU: 66.90s/epoch\n",
            "GPU: 12.14s/epoch\n",
            "Speedup (per-epoch): 5.5×\n"
          ]
        }
      ]
    }
  ]
}